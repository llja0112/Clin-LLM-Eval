{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_no = 44\n",
    "candidate_model = \"gpt-mini\"\n",
    "case_no_string = str(case_no).zfill(2)\n",
    "eval_model_case = candidate_model + \"-\" + case_no_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "case_dir = \"Data/cases/\"\n",
    "output_dir = \"Data/output/\"\n",
    "eval_dir = \"Data/evaluation/\"\n",
    "\n",
    "history = pd.read_csv(output_dir + \"history/\" + eval_model_case + \".csv\", index_col=0)\n",
    "physical = pd.read_csv(output_dir + \"physical/\" + eval_model_case + \".csv\", index_col=0)\n",
    "investigations = pd.read_csv(output_dir + \"investigations/\" + eval_model_case + \".csv\", index_col=0)\n",
    "diagnosis = pd.read_csv(output_dir + \"diagnosis/\" + eval_model_case + \".csv\", index_col=0)\n",
    "\n",
    "history_taking_checklist = pd.read_csv(case_dir + \"history/\" + str(case_no) + \".csv\", index_col=0)\n",
    "physical_checklist = pd.read_csv(case_dir + \"physical/\" + str(case_no) + \".csv\", index_col=0)\n",
    "investigations_checklist = pd.read_csv(case_dir + \"investigations/\" + str(case_no) + \".csv\", index_col=0)\n",
    "diagnosis_checklist = pd.read_csv(case_dir + \"diagnosis/\" + str(case_no) + \".csv\", index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from simulator import agents\n",
    "from simulator import retrievers\n",
    "import math\n",
    "reload(agents)\n",
    "reload(retrievers)\n",
    "\n",
    "doctor = history['Message']['HumanMessage']\n",
    "patient = history['Message']['AIMessage']\n",
    "\n",
    "conversation = []\n",
    "for d, p in zip(doctor, patient):\n",
    "  d = d.replace(\"\\n\", \" \")\n",
    "  p = str(p).replace(\"\\n\", \" \")\n",
    "  conversation.append(f\"Doctor: {d} | Patient: {p}\")\n",
    "conversation_flat = \"\\n\".join(conversation)\n",
    "\n",
    "simulatedExaminer = agents.ExaminerAgent(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "output = simulatedExaminer.evaluate_history_taking(conversation_flat, history_taking_checklist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_evaluation = pd.DataFrame([(output_item.score, output_item.explanation) for output_item in output], columns=[\"Score\", \"Explanation\"])\n",
    "history_evaluation.to_csv(eval_dir + \"history/\" + eval_model_case + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from simulator import agents\n",
    "from simulator import retrievers\n",
    "reload(agents)\n",
    "reload(retrievers)\n",
    "\n",
    "simulatedExaminer = agents.ExaminerAgent(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "physical_exam_suggestions = \"\"\n",
    "for _, row in physical.iterrows():\n",
    "  physical_exam_suggestions += \"Suggestion: \" + row['Physical Exam'] + \" | Justification: \" + row[\"Justification\"] + \"\\n\"\n",
    "\n",
    "output = simulatedExaminer.evaluate_physical_exam(physical_exam_suggestions, physical_checklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_evaluation = pd.DataFrame([(output_item.score, output_item.explanation) for output_item in output], columns=[\"Score\", \"Explanation\"])\n",
    "physical_evaluation.to_csv(eval_dir + \"physical/\" + eval_model_case + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from simulator import agents\n",
    "from simulator import retrievers\n",
    "reload(agents)\n",
    "reload(retrievers)\n",
    "\n",
    "simulatedExaminer = agents.ExaminerAgent(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "investigations_suggestions = \"\"\n",
    "for _, row in investigations.iterrows():\n",
    "  investigations_suggestions += \"Suggestion: \" + row['Investigation'] + \" | Justification: \" + row[\"Justification\"] + \"\\n\"\n",
    "\n",
    "output = simulatedExaminer.evaluate_investigations(investigations_suggestions, investigations_checklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "investigations_evaluation = pd.DataFrame([(output_item.score, output_item.explanation) for output_item in output], columns=[\"Score\", \"Explanation\"])\n",
    "investigations_evaluation.to_csv(eval_dir + \"investigations/\" + eval_model_case + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from simulator import agents\n",
    "from simulator import retrievers\n",
    "reload(agents)\n",
    "reload(retrievers)\n",
    "\n",
    "simulatedExaminer = agents.ExaminerAgent(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "diagnosis_suggestions = \"\"\n",
    "for _, row in diagnosis.iterrows():\n",
    "  diagnosis_suggestions += row['Diagnosis'] + \"\\n\"\n",
    "\n",
    "output = simulatedExaminer.evaluate_ddx(diagnosis_suggestions, diagnosis_checklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_evaluation = pd.DataFrame([(output_item.score, output_item.explanation) for output_item in output], columns=[\"Score\", \"Explanation\"])\n",
    "diagnosis_evaluation.to_csv(eval_dir + \"diagnosis/\" + eval_model_case + \".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
